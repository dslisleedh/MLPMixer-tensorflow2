{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dd954c-34b4-49c0-b7e7-f40cb1cce93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150bd358-851c-484f-a3cb-7beb73cafe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\datasets\\img_align_celeba\\img_align_celeba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1d743c-2e0f-432f-baae-748506827842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = pd.read_csv('C:/datasets/list_attr_celeba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfca283f-2a2b-433e-83ea-a41d05b14a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = tag[['image_id','Male']]\n",
    "tag.Male = np.where(tag.Male == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbf535d-ad5b-4921-928e-cf2525021f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93241</th>\n",
       "      <td>093242.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121413</th>\n",
       "      <td>121414.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>010625.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82523</th>\n",
       "      <td>082524.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73192</th>\n",
       "      <td>073193.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36890</th>\n",
       "      <td>036891.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>001993.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47852</th>\n",
       "      <td>047853.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79821</th>\n",
       "      <td>079822.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59328</th>\n",
       "      <td>059329.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162079 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  Male\n",
       "93241   093242.jpg     1\n",
       "121413  121414.jpg     0\n",
       "10624   010625.jpg     1\n",
       "82523   082524.jpg     0\n",
       "73192   073193.jpg     0\n",
       "...            ...   ...\n",
       "36890   036891.jpg     1\n",
       "1992    001993.jpg     0\n",
       "47852   047853.jpg     0\n",
       "79821   079822.jpg     0\n",
       "59328   059329.jpg     0\n",
       "\n",
       "[162079 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tag.sample(frac = .8, random_state=42)\n",
    "test = tag.drop(train.index)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d59c41-e93a-4beb-9eeb-b5f34a79bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa001c9d-79ae-4ff0-ac9d-7daf3435d1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121560 validated image filenames.\n",
      "Found 40519 validated image filenames.\n",
      "Found 40520 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory = directory,\n",
    "x_col=\"image_id\",\n",
    "y_col=\"Male\",\n",
    "subset=\"training\",\n",
    "batch_size=16,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "    class_mode='raw',\n",
    "target_size=(256,256))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory=directory,\n",
    "x_col=\"image_id\",\n",
    "y_col=\"Male\",\n",
    "subset=\"validation\",\n",
    "batch_size=16,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(256,256))\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test,\n",
    "directory=directory,\n",
    "x_col=\"image_id\",\n",
    "y_col='Male',\n",
    "batch_size=16,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode='raw',\n",
    "target_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16b0222-e10b-4e46-94b3-622980dbc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "    \n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1], \n",
    "            padding = 'VALID'\n",
    "        )\n",
    "        patches = tf.reshape(patches, (batch_size, -1, self.patch_size*self.patch_size*3))\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e65f4b1-bbe5-4489-b57d-26ab4438660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self, row_size, kernel_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.row_size = row_size\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(self.kernel_size, 1, input_shape = (self.row_size, self.kernel_size))\n",
    "        self.conv2 = tf.keras.layers.Conv1D(self.kernel_size, 1)\n",
    "        \n",
    "    def call(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = tf.nn.gelu(X)\n",
    "        X = self.conv2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f279bdfd-3638-4482-81be-9daf2b958ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixer_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_patches, hidden_chaneel_size):\n",
    "        super(Mixer_block, self).__init__()\n",
    "        self.n_patches = n_patches\n",
    "        self.hidden_chaneel_size = hidden_chaneel_size\n",
    "        \n",
    "        self.ln = tf.keras.layers.LayerNormalization(axis = 1)\n",
    "        self.t = tf.keras.layers.Permute((2,1))\n",
    "        self.mlp1 = MLP(self.hidden_chaneel_size, self.n_patches)\n",
    "        self.mlp2 = MLP(self.n_patches, self.hidden_chaneel_size)\n",
    "        \n",
    "    def call(self, X):\n",
    "        skip_X = X\n",
    "        X = self.ln(X)\n",
    "        X = self.t(X)\n",
    "        X = self.mlp1(X)\n",
    "        X = self.t(X)\n",
    "        X = X  + skip_X\n",
    "        skip_X2 = X\n",
    "        X = self.ln(X)\n",
    "        X = self.mlp2(X)\n",
    "        X = X + skip_X2\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e10f69f-aa84-4255-b309-a56d23e5c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Mixer(tf.keras.models.Model):\n",
    "    def __init__(self, patch_size:int, image_size:int, hidden_channel_size:int, n_mixers:int, fc_nodes:int, fc_layers:int):\n",
    "        tf.random.set_seed(42)\n",
    "        super(MLP_Mixer, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.image_size = image_size\n",
    "        if (image_size % patch_size) != 0:\n",
    "            raise ValueError('size error')\n",
    "        self.n_patches = int((tf.square(self.image_size) / tf.square(self.patch_size)).numpy())\n",
    "        self.hidden_channel_size = hidden_channel_size\n",
    "        self.n_mixers = n_mixers\n",
    "        self.fc_nodes = fc_nodes\n",
    "        self.fc_layers = fc_layers\n",
    "        \n",
    "        self.get_patch = Patches(self.patch_size)\n",
    "        self.ppfc = tf.keras.layers.LocallyConnected1D(self.hidden_channel_size, 1, input_shape = (self.n_patches, np.square(self.patch_size)*3))\n",
    "        self.mixer_blocks = [Mixer_block(self.n_patches, self.hidden_channel_size) for _ in range(self.n_mixers)]\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.fc = [tf.keras.layers.Dense(self.fc_nodes, activation = tfa.activations.gelu, kernel_initializer = tf.keras.initializers.lecun_normal(seed = i)) for i in range(self.fc_layers)]\n",
    "        self.classifier = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        \n",
    "    def call(self, X):\n",
    "        X = self.get_patch(X)\n",
    "        X = self.ppfc(X)\n",
    "        for mixer in self.mixer_blocks:\n",
    "            X = mixer(X)\n",
    "        X = self.gap(X)\n",
    "        for fc_layer in self.fc:\n",
    "            X = fc_layer(X)\n",
    "        X = self.classifier(X)\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f31534-1512-44de-b8c8-9f4f2a2abb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mixer = MLP_Mixer(64, 256, 512, 5, 512, 2)\n",
    "opt = tf.keras.optimizers.Adam(.0002)\n",
    "mlp_mixer.compile(optimizer=opt, loss=tf.losses.binary_crossentropy, metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2efd8b25-2f9c-4f84-956b-1b5d963fc4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soymi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7597/7597 [==============================] - 335s 44ms/step - loss: 0.2545 - acc: 0.8913 - val_loss: 0.2311 - val_acc: 0.9058\n",
      "Epoch 2/10\n",
      "7597/7597 [==============================] - 330s 43ms/step - loss: 0.1794 - acc: 0.9280 - val_loss: 0.1822 - val_acc: 0.9228\n",
      "Epoch 3/10\n",
      "7597/7597 [==============================] - 331s 44ms/step - loss: 0.1588 - acc: 0.9354 - val_loss: 0.1493 - val_acc: 0.9404\n",
      "Epoch 4/10\n",
      "7597/7597 [==============================] - 331s 44ms/step - loss: 0.1453 - acc: 0.9425 - val_loss: 0.1527 - val_acc: 0.9395\n",
      "Epoch 5/10\n",
      "7597/7597 [==============================] - 333s 44ms/step - loss: 0.1361 - acc: 0.9460 - val_loss: 0.1656 - val_acc: 0.9339\n",
      "Epoch 6/10\n",
      "7597/7597 [==============================] - 336s 44ms/step - loss: 0.1271 - acc: 0.9487 - val_loss: 0.1384 - val_acc: 0.9452\n",
      "Epoch 7/10\n",
      "7597/7597 [==============================] - 332s 44ms/step - loss: 0.1190 - acc: 0.9530 - val_loss: 0.1229 - val_acc: 0.9529\n",
      "Epoch 8/10\n",
      "7597/7597 [==============================] - 333s 44ms/step - loss: 0.1142 - acc: 0.9551 - val_loss: 0.1337 - val_acc: 0.9471\n",
      "Epoch 9/10\n",
      "7597/7597 [==============================] - 330s 43ms/step - loss: 0.1079 - acc: 0.9576 - val_loss: 0.1224 - val_acc: 0.9509\n",
      "Epoch 10/10\n",
      "7597/7597 [==============================] - 335s 44ms/step - loss: 0.1012 - acc: 0.9602 - val_loss: 0.1198 - val_acc: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b802f8e790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "mlp_mixer.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
